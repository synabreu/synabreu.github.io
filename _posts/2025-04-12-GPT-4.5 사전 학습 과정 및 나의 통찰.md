OpenAI의 핵심 팀 멤버인 알렉스(Alex), 아민 치안(Amin Chian), 단(Dan)과의 인터뷰를 바탕으로 GPT-4.5 모델의 사전 학습 과정에 대한 심층적인 내용을 다뤘다. GPT 4.5 모델 출시 후 예상보다 뜨거웠던 사용자 반응에 대한 감회를 시작으로, 거대 모델 개발의 복잡성, 기술적 난관, 데이터 효율성, 시스템 설계, 그리고 미래 모델 확장에 대한 통찰력 있는 오픈AI에서 공개한  “Pre-Training GPT-4.5” 유투브 비디오를 보고 간단하게 요약 정리해보았다.

**전체 개요** 

* GPT-4.5 모델 개발 과정을 담고 있으며, 모델 개발에 참여한 핵심 팀원들이 모여 모델을 만드는 데 필요한 노력, 시간, 컴퓨팅 자원에 대해 논의함. 
* 2년 전부터 시작된 프로젝트의 준비 과정, 대규모 컴퓨팅 클러스터 활용, 그리고 ML과 시스템 측면의 협업을 강조함. 
* 모델 훈련 중 예상치 못한 기술적 난관과 이를 해결해 나가는 과정과 GPT-4 대비 10배 향상된 성능 목표 달성에 대한 이야기가 주를 이룸. 
* 향후 모델 확장과 데이터 효율성에 대한 전망도 제시함. 

**1. GPT-4.5 개발 과정의 복잡성:**

- **장기간의 노력:** GPT-4.5 개발은 실제 학습 시작 2년 전부터 시작되었으며, 새로운 컴퓨팅 클러스터 구축 계획에 맞춰 기능 정의, 위험 제거(derisking), 상세 계획 수립 등 풀 스택에 걸친 광범위한 준비 작업이 이루어졌다.
- **ML과 시스템의 긴밀한 협업:** 모델 개발은 초기 구상 단계부터 ML 연구팀과 시스템 아키텍처 팀 간의 긴밀한 협력을 요구했으며, 이는 모델 학습 실행 단계까지 지속되었다.
- **예측 불가능성과 문제 해결:** 모델 학습 과정은 예측대로 흘러가지 않는 경우가 많으며, 항상 해결해야 할 미결 문제가 존재한다. 초기 시스템 구축 단계에서는 예상과 큰 차이를 보이는 경우가 많으며, 출시를 늦출 것인지 아니면 문제를 해결하면서 진행할 것 인지에 대한 균형 잡힌 의사 결정이 중요하다.
- **대규모 GPU 시스템의 어려움:** GPU 수를 1만 개에서 10만 개로 늘리는 것과 같은 대규모 확장은 단순히 자원 증가 이상의 복잡성을 야기한다. 작은 규모에서는 드물게 발생하는 문제가 대규모에서는 치명적인 오류로 나타날 수 있으며, 인프라, 네트워크, 개별 가속기 등 모든 구성 요소가 예상대로 작동해야 결과의 신뢰성을 확보할 수 있다.

**2. GPT-4.5의 성능 및 목표:**

- **GPT 4 대비 10배 향상 목표:** GPT-4.5 프로젝트의 초기 목표는 GPT-4 대비 "10배 더 스마트"한 모델을 만드는 것이었으며, 최종적으로 이러한 목표를 달성했다고 평가한다. 사용자들은 GPT-4.5가 GPT-4와 확연히 다르며, 설명하기 어렵거나 명확한 여러 측면에서 훨씬 뛰어나다고 평가했다.
- **예상치 못한 능력:** GPT-4.5는 개발팀이 예상하지 못했던 미묘하고 다채로운 능력을 보여주었으며, 이는 사전 학습을 통한 모델 지능 향상의 예측 불가능성과 잠재력을 시사한다. 특히, 배포 과정에서, 사용자 만족도에서, 모델이 매우 미묘한 방식으로 더 똑똑하다는 것을 알 수 있었다. 또한, 더 많은 상식 지식을 가지고 있고, 뉘앙스와 맥락을 더 잘 이해한다. 
- **개선된 효율성:** GPT-4.5 연구 프로그램을 통해 GPT-4 수준의 모델을 재학습하는 데 필요한 인력이 5~10명 수준으로 줄어드는 등, 모델 개발 및 학습 스택의 효율성이 크게 향상되었다.

**3. 미래 확장을 위한 과제:**

- **데이터 효율성의 중요성 강조:** Transformer는 데이터를 매우 효율적으로 활용하는 데 탁월하며, 정보를 흡수하고 압축하며 어느 정도 일반화한다. 하지만 데이터에서 얻을 수 있는 깊이 있는 통찰력에는 어느 정도 한계가 있다. 따라서 컴퓨팅은 계속 증가하지만 데이터는 훨씬 느리게 증가하면 데이터가 표준 패러다임의 병목 지점이 되며, 동일한 양의 데이터에서 더 많은 것을 학습하기 위해 더 많은 컴퓨팅을 사용하는 알고리즘 혁신이 필요하다. 
- **시스템 확장성 및 안정성:** 다음 단계의 10배, 100배 규모 확장을 위해서는 시스템 측면에서도 상당한 발전이 필요하다. GPT-4와 GPT-4.5 사이에도 모델 사양 변경에 따라 시스템 아키텍처, 상태 관리 방식, 다중 클러스터 학습 등 많은 변화가 요구되었다. 미래에는 결함 허용(fault tolerance) 능력을 워크로드와 공동 설계하여 운영 부담을 줄이는 것이 중요해질 것이다.
- **하드웨어 한계:** 현재 시스템 확장의 병목 지점이 명확히 규정하기는 어렵다. 모델 설계에 따라 자원 요구 사항을 조정하여 균형 잡힌 시스템을 구축할 수 있다. 하지만 메모리 대역폭 증가는 항상 도움이 될 것이다. 네트워크 전송 수준에서 오류 발생 시 애플리케이션 수준보다 더 낮은 수준에서 복구할 수 있는 기능이 있다면 시스템 안정성 향상에 기여할 것이다.

**4. 학습 과정에서의 경험 및 통찰:**

- **실패 속에서의 배움:** 초기 하드웨어 세대에서는 예상치 못한 오류 발생률이 높으며, 학습 과정에서 이러한 오류의 근본 원인을 파악하고 해결하는 과정이 중요하다. 초기 단계의 어려움에도 불구하고, 문제 해결 후에는 실패율이 현저히 감소하고 시스템 가동 시간이 개선되는 경향을 보인다.
- **예상 밖의 버그:** 학습 과정에서 발생한 다양한 증상의 오류들이 PyTorch의 기본적인 합산(summation) 함수 내의 버그라는 단일 원인으로 밝혀진 흥미로운 경험이 있었다. 이는 거대 모델 학습의 복잡성과 예상치 못한 곳에서 문제가 발생할 수 있음을 보여준다.
- **지속적인 모니터링 및 개선:** 학습 과정이 시작된 후에도 손실 곡선(loss curve) 및 기타 통계 지표를 지속적으로 모니터링하고, 시스템 및 ML 측면에서 개선 작업을 진행한다. 예측과 다른 추세가 나타나는지 주의 깊게 살피고, 런타임 개선을 위한 노력을 지속한다.
- **팀워크 및 협업:** 문제 해결 과정에서 팀원 간의 적극적인 협력과 책임감 있는 자세가 중요하며, 각자의 역할을 넘어 공동의 목표 달성을 위해 노력하는 문화가 성공적인 모델 개발에 기여한다.

**5. 데이터 효율성 및 스케일링 법칙:**

- **데이터 효율성의 중요성:** 현재 딥러닝 연구는 컴퓨팅 효율성에 집중되어 왔지만, 데이터가 제한적인 상황에서는 데이터 효율성을 높이는 연구가 중요해지고 있다. 인간의 데이터 효율성은 현재 최고 수준의 알고리즘과 비교했을 때 엄청나게 높은 수준이며, 향후 데이터 효율성 분야에서 상당한 발전이 있을 것으로 기대된다.
- **스케일링 법칙의 지속:** GPT 모델의 크기와 학습량을 늘릴수록 성능이 향상된다는 스케일링 법칙은 GPT-4.5 개발을 통해 다시 한번 검증되었다. 이는 더 큰 모델과 더 많은 데이터를 활용한 학습이 지속적으로 더 나은 성능을 제공할 가능성을 시사한다.
- **스케일링 법칙의 원리:** 더 많은 압축이 더 높은 지능으로 이어진다는 철학적 기반이 스케일링 법칙을 뒷받침한다. 더 큰 모델을 더 오래 학습시키는 것이 데이터 압축률을 높이는 이유에 대한 여러 이론이 존재하며, 그중 하나는 세상의 중요한 개념들이 데이터 내에서 희소하게 분포하고 있으며, 이러한 분포가 멱법칙(power law)을 따른다는 것이다.

**6. 평가 지표의 중요성:**

- **일반화 능력 측정:** 모델의 지능을 평가할 때 인간이 이해하기 쉬운 시험에 의존하는 것은 모델이 암기 능력을 향상시키는 데 집중하게 만들 수 있다. 따라서 학습 데이터와 겹치지 않는 홀드아웃(held-out) 데이터를 사용하여 모델의 일반화 능력을 측정하는 것이 중요하다.
- **퍼플렉서티(Perplexity):** 언어 모델의 성능을 평가하는 주요 지표 중 하나로, 모델이 텍스트를 얼마나 잘 예측하는지를 나타낸다. 하지만 퍼플렉서티 외에도 다양한 평가 지표를 종합적으로 고려해야 모델의 실제 성능을 정확하게 파악할 수 있다.
- **학습 데이터의 중요성:** 학습 데이터가 평가 데이터와 조금이라도 유사하다면 스케일링 법칙을 통한 성능 향상 효과를 정확하게 측정하기 어렵다. 따라서 평가 데이터가 학습 데이터에 전혀 포함되지 않았는지 확인하는 것이 매우 중요하다. OpenAI 내부 코드베이스는 학습 데이터에 포함되지 않아 모델의 일반화 능력을 평가하는 데 유용한 홀드아웃 데이터로 활용된다.

**결론**

GPT-4.5 사전 학습 과정에서 거대 언어 모델 개발의 복잡성과 도전 과제를 생생하게 보여줘서 개인적으로 흥미로웠다. GPT-4.5의 성공적인 개발은 장기간의 철저한 준비, ML과 시스템 팀의 긴밀한 협업, 예측 불가능한 문제들에 대한 유연한 대처, 그리고 끊임없는 기술 혁신이 있었기에 가능했다. 데이터 효율성 향상과 시스템 확장성 확보는 미래 모델 발전을 위한 핵심 과제이며, 스케일링 법칙은 여전히 유효하지만 그 근본적인 원리에 대한 심층적인 이해가 필요하다는 저의 생각과 동일해서 좋았다. 끝으로, 모델의 진정한 지능을 측정하기 위한 신뢰할 수 있는 평가 지표 개발의 중요성을 강조했다.

.**출처**

* Pre-Training GPT-4.5 : https://www.youtube.com/watch?v=6nJZopACRuQ

  
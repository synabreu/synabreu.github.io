---
title: "2025-02-25-DeepSeek, 분산 학습의 새로운 지평을 열다"
date: 2025-02-25
tags: [DeepSeek, MultiGPU, Collective Communication, NVIDIA NCCL, Facebook Gloo, Intel MPI, DeepEP, MoE, RDMA, NVLink, GPU, 저지연 커널, Low-latency Kernel, Group-limited Gating Algorithm]
typora-root-url: ../
---


최근 DeepSeek 사가 자사의 대규모 언어 모델 개발에 사용된 핵심 기술들을 오픈소스로 하나씩 공개하고 있어 업계의 큰 주목을 받고 있다. 단순히 하드웨어 자원 절감에 그치지 않고, **소프트웨어 스택과 알고리즘까지도 혁신적으로 최적화**했다는 점은 이미 공개된 여러 논문을 통해 확인할 수 있다. 특히, 눈에 띄는 **고성능 분산 통신 라이브러리 "DeepEP"**에 대해 분석한 내용을 정리해 보도록 하겠다.



## 멀티 GPU 분산 학습의 숙제

현재 AI 업계에서 학습과 추론의 성능을 극대화하기 위해, 여러 GPU 또는 노드를 활용한 분산 학습이 표준으로 자리잡고 있다. 이 과정에서 소프트웨어 엔지니어들은 **대규모 언어 모델을 어떻게 효율적으로 분산화할 것인가**라는 과제에 직면하게 된다.

대규모 모델 학습 시에는 모델 파라미터나 중간 계산 결과(예: 그래디언트, 활성화값 등)를 빠르고 안정적으로 전송할 수 있는 **Collective Communication 라이브러리**가 필수이다. 대표적으로는 **NVIDIA NCCL**, **Facebook Gloo**, **Intel MPI** 등이 사용되고 있다.



## DeepEP: MoE와 Expert Parallelism을 위한 커스텀 통신 최적화

DeepSeek이 이번에 공개한 **DeepEP(Deep Expert Parallelism)**은 특히 **MoE(Mixture-of-Experts)** 아키텍처를 위한 고성능 통신 라이브러리이다. 기존의 AllReduce 방식과는 달리, DeepEP는 다음과 같은 혁신적인 설계를 기반으로 하고 있다.

1. **Expert 병목 최소화**
   - GPU 하나 당 하나의 Expert만을 배치하는 방식(예: EP320 구성)으로 통신 경로 단순화 및 병목 제거
2. **RDMA 및 NVLink 기반의 저지연 통신**
   - GPU 간 직접 통신(RDMA)을 사용해 서버 간 Expert 데이터 전송을 극대화
3. **통신-연산 오버랩(Overlap) 구조**
   - 통신과 계산을 병렬적으로 수행하여 전체 지연 시간(latency)을 억제
4. **FP8 연산 지원**
   - 최신 GPU 아키텍처에서 더 적은 메모리 사용으로 높은 처리량을 확보

## MoE 최적화를 위한 핵심 커널 내장

DeepSeek-V3 논문에서 제안한 **Group-limited Gating Algorithm**을 기반으로 최적화된 커널을 탑재하고 있으며, 학습뿐 아니라 **추론 환경에서도 사용 가능**하다. 특히, 추론 시 디코딩 속도를 극대화하기 위한 **저지연 커널(Low-latency Kernel)**이 포함되어 있어 **실시간 응용 서비스에서도 탁월한 성능**을 발휘할 수 있다.

MoE 구조는 Expert 간 데이터 전송에서 병목이 자주 발생하지만, DeepEP는 이를 최적화된 GPU 커널과 통신 구조를 통해 극복했다. 특히 RDMA 기반 전송은 서버 간 Expert 연산 효율을 극적으로 향상시킨다.

## 마무리

DeepSeek의 오픈소스 행보는 단순한 모델 공개를 넘어서, 분산 학습의 전 과정을 최적화하는 방향으로 이어지고 있다. DeepSeek의 행보는 단순히 모델 성능의 향상에 그치지 않고, **AI 인프라와 알고리즘 전반에 걸친 혁신을 실현**하고 있음을 보여준다. 앞으로도 공개될 기술들이 기대되는 이유이다. 



* 오픈소스: https://github.com/deepseek-ai/DeepEP
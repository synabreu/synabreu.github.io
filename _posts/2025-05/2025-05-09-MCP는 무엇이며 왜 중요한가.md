---
title: "MCP는 무엇이며 왜 중요한가"
date: 2025-05-09
categories: [mcp, anthropic, openai, chatgpt]
tags: [mcp, anthropic, openai]
typora-root-url: ../
toc: true
---

AI 모델이 외부 시스템, API, 또는 도구와 직접 상호작용할 수 있도록 연결해주는 인터페이스를 우리는 **MCP (Model Context Protocol)**라고 부른다.  예를 들어, AI가 웹사이트를 탐색하거나, 이메일을 전송하거나, 클라우드 리소스를 제어하는 등의 행위를 수행할 수 있도록 돕는다. 일반적으로 MCP 서버는 Python 또는 Node.js 기반의 HTTP 서버로 구성되며, AI 툴킷(VS Code AI Tools 등)을 통해 모델이 이 MCP에 연결되어 명령을 실행할 수 있다. 그렇다면, 도대체 MCP는 무엇이며 왜 중요한 지를  한 번 정리해보자!



## 1. MCP 개념과 중요성

* 개요: AI 모델과 다양한 앱/데이터 소스 간의 연결을 표준화하는 MCP의 개념, 역사, 작동 방식, 장점, 한계점 분석
* MCP 정의: 
  * AI를 위한 범용 플러그, AI 모델이 다양한 앱 및 데이터 소스에 일관된 방식으로 연결되도록 지원하는 개방형 표준
  * **USB-C for AI Integrations:** 다양한 소프트웨어 도구와 공통 언어로 통신할 수 있도록 지원
* **AI 코딩 지원:** Cursor, Windsurf와 같은 AI 코딩 도우미가 외부 도구를 활용할 수 있도록 지원하는 공유 프로토콜
* **자연어 명령:** AI 모델이 데이터베이스에서 정보를 가져오고, Figma에서 디자인을 편집하고, 음악 앱을 제어하는 등의 작업을 자연어 명령을 통해 수행.



## 2. MCP의 역사적 맥락

* 초기 LLM의 한계: 텍스트 예측은 가능했지만 외부 도구나 실시간 데이터 사용 불가
* 2023년의 전환점: 
  * ChatGPT와 같은 AI 시스템이 도구 및 플러그인 통합 시작
  * OpenAI의 기능 호출 및 플러그인: 모델이 코드를 실행하고, 웹 브라우징을 사용하고, API를 호출할 수 있도록 지원
  * LangChain, AutoGPT 등의 프레임워크 등장: 다단계 "에이전트" 동작 가능
  * 도구 지원 에이전트의 등장: 소프트웨어 도구를 통해 관찰, 계획, 실행 가능
  * Anthropic의 MCP 도입 (2024년): LLM의 연결성 표준화 필요성 인식.
* **텍스트 예측에서 도구 지원 에이전트로의 진화**



## 3. MCP가 해결하는 문제점

* 파편화된 통합 문제: AI IDE가 GitHub에서 코드를 가져오고, 데이터베이스에서 데이터를 가져오고, 디자인 도구를 자동화하는 데 각각 다른 방법 사용
* 앤트로픽의 지적: 가장 정교한 모델조차 데이터로부터 고립되어 정보 사일로에 갇혀 있다. 새로운 데이터 소스마다 자체적인 구현이 필요하므로 진정으로 연결된 시스템을 확장하기 어렵다.
  * 도구 간 언어 불일치 문제: 각 소프트웨어 또는 서비스가 자체 API, 데이터 형식, 어휘를 가지고 있어 AI 에이전트가 이를 모두 알아야 함
  * MCP의 해결책: 공통 프로토콜을 제공하여 모든 상호 작용을 표준화하고, 도구가 자체 기능을 표준화된 방식으로 선언할 수 있도록 지원
  * MCP 아키텍처: 클라이언트, 프로토콜, 서버, 서비스



## 4. MCP 아키텍처

* **MCP 아키텍처:** 클라이언트, 프로토콜, 서버, 서비스
* **MCP 서버:** 특정 애플리케이션 또는 서비스와 함께 실행되는 경량 어댑터
  * 기능: 애플리케이션 기능 표준화된 방식으로 노출, 자연어 요청을 앱의 해당 동작으로 변환.
  * Blender MCP 서버 예시: "큐브를 만들고 나무 질감을 적용"과 같은 요청을 Blender의 Python API 호출로 매핑.
  * GitHub MCP 서버 예시: "내 공개 풀 요청 목록"을 가져와 GitHub API를 통해 가져옴.
  * 주요 기능: 도구 검색, 명령 구문 분석, 응답 형식 지정, 오류 처리.
*  **MCP 클라이언트:** AI 어시스턴트(또는 플랫폼)에 포함된 구성 요소
  * 역할: MCP 서버와의 1:1 연결 유지, 통신 처리, 서버 응답을 AI 모델에 제공.
  * MCP 클라이언트 관리자: Cursor와 같은 AI "호스트" 프로그램이 Figma 또는 Ableton 서버와 통신하기 위해 MCP 클라이언트 실행.
* **MCP 프로토콜:** 클라이언트와 서버 간의 통신 언어 및 규칙 정의
  * 내용: 메시지 형식, 서버가 사용 가능한 명령을 알리는 방법, AI가 질문하거나 명령을 내리는 방법, 결과 반환 방법 등 정의.
  * 전송 방식: HTTP/WebSocket(원격 또는 독립 실행형 서버), 표준 I/O 스트림(stdin/stdout, 로컬 통합) 등 전송 방식에 구애받지 않음.
  * 메시지 내용: JSON 또는 다른 구조화된 스키마 사용 (JSON 스키마 정의).
* **서비스 (애플리케이션/데이터 소스):** AI가 궁극적으로 활용하고자 하는 앱, 데이터베이스 또는 시스템
  * 유형: 로컬(파일 시스템, Excel 파일, Blender 인스턴스) 또는 원격(Slack, GitHub API를 통해 액세스) 서비스.
  * MCP 서버의 역할: AI를 대신하여 이러한 서비스에 안전하게 액세스.



## 5. MCP가 AI 에이전트 및 개발자 도구에 미치는 영향

* **AI 에이전트의 기능 확장 및 설계 간소화:** 하드 코딩된 기능 대신 MCP를 통해 새로운 도구를 동적으로 검색하고 사용 가능
  * 새로운 기능 추가 용이성: 모델을 재학습하거나 핵심 시스템을 변경하지 않고 MCP 서버를 실행하여 AI 어시스턴트에 새로운 기능 제공.
* **개발자 도구 관점:** 개발 워크플로우를 간소화하고 생산성 향상
  * **다양한 도구 간의 원활한 전환:** AI 코드veloper가 IDE, GitHub, Jira, Figma, CI 파이프라인, 브라우저 등 다양한 도구를 원활하게 전환 가능.
  * **디자인-코드 통합:** AI IDE가 Figma에서 디자인 사양을 가져와 코드를 생성하여 수동 단계와 잠재적 의사 소통 오류 제거.
  * **벤더 종속성 감소:** MCP는 개방형 표준이므로 모든 AI 클라이언트(Claude, 기타 LLM 챗봇, 오픈 소스 LLM)가 모든 MCP 서버 사용 가능.
* **MCP 우선 개발:** AI가 앱을 구동할 수 있도록 앱용 MCP 서버를 GUI와 함께 또는 GUI보다 먼저 구축하는 방식
  * 초기 도입자들의 이점: Unity MCP 서버를 통해 Claude에게 복잡한 게임 개발 워크플로우 실행 요청 가능.



## 6. MCP의 한계 및 과제

* 파편화된 채택 및 호환성: 모든 AI 플랫폼 또는 모델이 MCP를 기본적으로 지원하지 않음
  * Claude와 관련 도구의 선두: Anthropic의 Claude가 MCP를 기본적으로 지원하고, Cursor 및 Windsurf와 같은 도구가 지원을 추가했지만, ChatGPT 또는 로컬 Llama 모델은 아직 직접적인 MCP 지원이 없을 수 있음.
* 신뢰성 및 AI 이해도: AI가 도구 설명을 통해 수행할 수 있는 작업을 이해하고, 언제 무엇을 해야 하는지 정확히 판단해야 함
  * AI 에이전트의 불완전성: AI가 도구를 오용하거나 복잡한 작업에서 혼동을 일으킬 수 있음.

* 보안 및 안전 문제: AI가 원치 않는 작업을 수행할 가능성 존재 (데이터 삭제, 정보 유출, API 스팸 등)
  * 인증 및 권한 부여: 다중 사용자 시나리오에 대한 공식화된 인증 메커니즘 부재.
  * 권한 설정: AI 에이전트가 필요한 권한만 갖도록 보장하는 시스템 부재.
  * AI 또는 인간에 의한 오용: 악의적인 프롬프트 주입을 통해 AI가 유해한 방식으로 도구를 사용하도록 유도 가능.

* 성능 및 대기 시간: 각 MCP 호출은 외부 작업이므로 AI의 내부 추론보다 훨씬 느릴 수 있음
  * 캐싱, 병렬화 호출 등의 최적화 필요.
  * 다단계 트랜잭션의 부재: AI가 일련의 MCP 작업을 사용하여 작업을 수행할 때 작업이 중간에 실패할 경우 롤백되지 않음
* 학습 데이터 제한 및 최신성: AI 모델이 특정 시점까지의 데이터로 학습되었으므로 MCP 또는 특정 서버에 대한 지식이 없을 수 있음
  * 인간의 감독 및 신뢰: AI가 작업을 수행하도록 신뢰하는 데 대한 사용자의 불안감 해소 필요
* 확장성 및 멀티 테넌시: 현재 MCP 서버는 종종 단일 사용자용으로, 멀티 테넌시(하나의 MCP 서버가 여러 독립 에이전트 또는 사용자에게 서비스 제공)는 아직 많이 연구되지 않음
* 표준 성숙도: MCP는 아직 새로운 기술이므로 엣지 케이스 및 요구 사항이 발견됨에 따라 사양 자체에 대한 반복 작업이 필요할 수 있음



## 7. MCP 서버 구축 및 통합 방법

* **애플리케이션의 제어 지점 식별:** REST API, Python/Ruby/JS API, 플러그인 메커니즘 등을 통해 애플리케이션을 프로그래밍 방식으로 제어하거나 쿼리하는 방법 파악
  * MCP SDK/템플릿을 사용하여 서버 스캐폴드: MCP 프로토콜 프로젝트에서 제공하는 SDK를 사용하여 서버 구축
  * 서버 기능 정의 (도구): 서버가 수행할 수 있는 작업, 입력/출력, 설명 등을 지정하여 AI가 볼 인터페이스 설계
  * 명령 구문 분석 및 실행 구현: 작업이 호출될 때 실제로 발생하는 코드 작성 (애플리케이션 또는 서비스 호출)
* **통신 설정 (전송):** AI가 서버와 통신할 방법 결정 (stdio, HTTP 또는 WebSocket 서버)
  * AI 클라이언트로 테스트: 실제 AI 모델로 MCP 서버 테스트 (Claude 또는 MCP 지원 프레임워크)
  * 오류 처리 및 안전 구현: 유효하지 않거나 범위를 벗어난 요청을 정상적으로 처리하고, 시간 초과 및 위험한 작업 방지
* **인증 및 권한 (필요한 경우):** 민감한 데이터에 액세스하거나 인증이 필요한 경우 (클라우드 서비스용 API 키) 구축
  * 문서화 및 게시: 다른 사용자가 MCP 서버를 사용할 수 있도록 기능 및 실행 방법 문서화
  * 반복 및 최적화: 실제 사용을 통해 배우고, 새로운 명령으로 서버 확장, 사용되지 않거나 위험한 명령 비활성화 또는 개선



## 8. 결론

* MCP는 개발자를 위한 범용 AI 어시스턴트의 꿈을 현실로 만들고, 도구를 컨텍스트 인식 및 상호 운용 가능하게 만들어 생산성 향상 및 전략적 이점 제공
* 향후 전망: 인증 표준화, MCP 게이트웨이 생성, MCP 에이전트 개선 등을 통해 더욱 강력한 MCP 생태계 구축 기대
* 참고: [MCP: What It Is and Why It Matters—Part 1](https://www.oreilly.com/radar/mcp-what-it-is-and-why-it-matters-part-1/)


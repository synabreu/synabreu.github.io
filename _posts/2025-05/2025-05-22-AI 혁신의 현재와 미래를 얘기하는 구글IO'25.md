---
title: "AI 혁신의 현재와 미래를 얘기하는 구글IO'25"
date: 2025-05-23
tags: [구글, Google, Google I/O, Gemini, TPU,Android, DeepMind, Samsung, HP]
typora-root-url: ../
toc: true
categories: [Google]
---

구글 I/O '25 키노트에서 순다 피차이 CEO는 구글이 본격적인 'Gemini 시대'에 접어들었음을 선언하며, 이전보다 훨씬 빠른 속도로 최신 AI 모델과 연구 성과를 사용자 및 개발자에게 제공하고 있다고 밝혔다. 오늘은 구글 I/O '25 키노트를 핵심 요약을 해보자!



## 1. 구글 I/O 키노트 요약

* Gemini 2.5 시대 개막:  
  * Gemini 2.5 Pro·Flash가 각종 벤치마크 1‒2위를 석권, 코딩, 멀티모달, 롱 컨텍스트 능력 대폭 향상.
  *  ‘DeepThink’ 모드로 복잡한 문제 해결력 극대화, 신뢰 테스터 대상 곧 공개 예정
  * 폭발적 확산: 월간 처리 토큰 480조(+50× YoY), Gemini API 개발자 700만 +, Vertex AI 사용량 40×, Gemini 앱 MAU 4억, AI Overviews MAU 15억. 
* 새로운 AI 경험
  * Gemini Live: 카메라 및 화면 공유 기반 실시간 도우미
  *  Agent Mode: 복잡한 작업(아파트 검색 등) 자동화.
  * Google Beam(Starline 진화): 2D 화상통화를 실감 3D로 변환.
  *  AI Mode 검색: Gemini 2.5로 구동되는 차세대 검색, 오늘부터 미국 출시.
* 개발자 기능 강화 및 생태계 확대
  * 다중 화자 TTS, 사고 요약 및 예산으로 투명성과 비용 제어
  * 비동기 코딩 에이전트 Jules 베타, 초고속 텍스트 확산 Gemini Diffusion 공개
  * Imagen 4(이미지), Veo 3(비디오·오디오), Lyria 2(음악) 모델을 Vertex AI·Gemini 앱에 통합
  *  Android XR 플랫폼 및 삼성 Moohan 헤드셋 및 AI 안경 발표.
* 새 구독 플랜
  * Gemini AI Pro $19.99/월, Ultra $249.99/월(DeepThink·Veo 3·YouTube Premium 포함).



## 2. 더욱 더 발전한 Gemini 모델

* Gemini 2.5 Pro는 LM 아레나 리더보드 모든 카테고리에서 1위를 차지했으며, 이전 세대 대비 ELO 점수가 300점 이상 향상되었음
* 코딩 능력 크게 발전하여, 업데이트된 2.5 Pro는 Web Dev Arena에서 1위를 기록했고, 이전 버전보다 ELO 점수가 142점 높아졌음
*  Cursor와 같은 AI 코드 편집기에서 Gemini는 가장 빠르게 성장하는 모델로 자리 매김 했음
* 흥미롭게도 Gemini는 포켓몬 블루 게임을 완료하여 API(Artificial Pokemon Intelligence) 달성에 한 걸음 더 다가섰다고 소개했음



## 3. 강력한 초고성능 인프라

* 7세대 TPU Ironwood(포드당 42.5 EFLOPS)로 훈련 및 추론 비용은 줄이고,  속도는 높이고 올해 말 GCP 고객에게 제공할 예정
* TPU를 포함한 인프라 우위는 모델 가격은 낮추면서도 초당 생성 토큰 수에서 Gemini가 LM 아레나 리더보드 상위 3자리를 차지하는 등 빠르고 효율적인 모델을 가능하게 함



## 4. AI 연구 프로젝트의 현실화

* AI Overview 및 AI Mode : AI Overviews는 매월 15억명의 사용자 확보하고 있으며, AI Mode는 검색을 이을 큰 발전을 이루고 있음 
* Project Starline / Google Beam
  * 3D 비디오 통신 기술인 Project Starline이 'Google Beam'이라는 새로운 AI 우선 비디오 커뮤니케이션 플랫폼으로 발전했음. 
  * Beam은 2D 비디오 스트림을 현실적인 3D 경험으로 변환하며, HP와의 협력을 통해 올해 말 초기 고객에게 첫 번째 Google Beam 장치가 제공될 예정임
* Google Meet 실시간 번역: Starline의 기술은 Google Meet에도 적용되어 실시간 음성 번역 기능을 제공함. 예) 영어-스페인어 번역이 현재 구독자에게 제공되며, 더 많은 언어가 추가될 예정
* Project Astra / Gemini Live: 
  * 주변 세계를 이해하는 범용 AI 비서 프로젝트인 Astra의 카메라 및 화면 공유 기능이 Gemini Live에 통합되었음. 
  * Android 및 iOS 사용자에게 오늘부터 제공함
* Project Mariner / Computer Use: 
  * 웹과 상호작용하고 작업을 수행할 수 있는 에이전트인 Project Mariner는 멀티태스킹(최대 10개 동시 작업)과 'Teach and Repeat'(한 번 학습 후 유사 작업 수행) 기능을 도입했음
  * Mariner의 Computer Use 기능은 Gemini API를 통해 개발자에게 제공되며, Automation Anywhere, UI Path 등이 이미 테스트 중임
* A2A / MCP Support :  에이전트 간 통신 프로토콜인 A2A 제공하며, 이제 Gemini SDK는 MCP 도구와 호환됨
* Agent Mode in Gemini App: 
  * 에이전트 기능은 Gemini 앱의 'Agent Mode'를 통해 사용자가 아파트 검색과 같은 복잡한 작업을 수행하는 데 도움을 줌. 
  * Zillow와 같은 사이트에서 조건에 맞는 매물을 찾고 투어 예약을 지원함.
  * Agent Mode 실험 버전은 곧 구독자에게 제공될 예정임



## 5. AI 경험의 개인화

* '개인 컨텍스트(personal context)'를 통해 사용자의 Google 앱 전반에 걸친 관련 정보를 활용하여 Gemini 모델을 더욱 개인화하고 있음
* Gmail의 '개인화된 스마트 답장' 기능은 사용자의 이전 이메일, 드라이브 문서 등을 참조하여 사용자의 스타일과 톤에 맞는 답장을 생성함. 올여름 Gmail 구독자에게 제공될 예정.
* 내가 자주 쓰는 단어나 패턴을 인식해서 이메일 답장을 내 말투로 작성해줌



## 6. Google DeepMind: Gemini 모델의 진화와 미래 연구

* 데미스 하사시스는 Gemini 2.5 Pro가 세계 최고의 파운데이션 모델임을 재확인하며, 교육 전문가와 함께 구축한 LearnLM을 통합하여 학습 분야에서도 최고의 모델이 되었다고 밝혔음.

* Gemini 2.5 Flash 업데이트

  * 속도 향상과 저비용으로 인기 있는 효율적인 모델인 Gemini Flash의 업데이트 버전이 공개했음. 
  * 새로운 Flash는 추론, 코드, 긴 컨텍스트 전반에서 개선되어 LM 아레나 리더보드에서 2.5 Pro에 이어 2위를 차지했음. 
  * Flash는 6월 초, Pro는 곧이어 정식 출시될 예정이며, Gemini App 에서 Preview 제공

* Gemini 2.5 Pro DeepThink

  * 모델 성능을 극한까지 끌어올리는 'DeepThink' 모드가 새롭게 소개되었음
  * DeepThink는 병렬 처리 기술 등 최신 연구를 활용하여 USA Mo 2025 (수학), Live Codebench (코딩) 등 어려운 벤치마크에서 뛰어난 성능을 보였음.
  * 안전성 평가 및 전문가 의견 수렴 후 Gemini API를 통해 신뢰할 수 있는 테스터에게 우선 제공될 예정

* 월드 모델(World Model)과 로보틱스

  * Gemini를 단순히 멀티모달을 넘어 세계를 시뮬레이션하고 계획을 세우며 새로운 경험을 상상할 수 있는 '월드 모델'로 확장하는 연구가 진행 중
  * 로보틱스 분야에도 중요하며, 이미 로봇이 작업을 수행하고 새로운 작업에 적응하도록 학습시키는 특수 모델 'Gemini Robotics'가 개발되었음

* Project Astra의 진화: 

  * 작년에 처음 선보인 Project Astra는 비디오 이해, 화면 공유, 메모리 기능 등이 Gemini Live에 통합되고 있음. 
  * 더 나아가 자연스러운 음성 출력, 향상된 메모리, 컴퓨터 제어 기능 등이 추가된 최신 프로토타입이 시연함. 
  * Gemini Live, Search, Live API, Android XR 안경 등 다양한 형태로 제공될 예정임

* 과학 연구 가속화: 

  * AlphaProof (수학 올림피아드 문제 해결), AlphaFold 3 (모든 생명 분자의 구조 및 상호작용 예측), Isomorphic Labs (AI 기반 신약 개발) 등 AI를 활용한 과학적 발견이 가속화되고 있음
  * AlphaFold는 이미 전 세계 250만 명 이상의 연구자가 사용하고 있음

  

## 7. 개발자를 위한 Gemini 

* **향상된 텍스트-음성 변환(TTS)**

  * 새로운 2.5 Flash와 함께, 업계 최초로 두 가지 음성에 대한 다중 화자 지원 기능을 갖춘 TTS 미리보기가 공개되었음
  * 향상된 Gemini 모델은 미묘한 뉘앙스를 포착하고 속삭이는 듯한 표현도 가능하며, 24개 이상의 언어 간 전환이 자연스럽고, Gemini API에서 오늘부터 사용 가능함

* **강화된 보안 및 투명성:** 간접 프롬프트 주입과 같은 보안 위협에 대한 보호 기능이 강화되었고, Gemini API 및 Vertex AI를 통해 모델의 사고 과정을 명확한 형식으로 제공하는 '사고 요약(thought summaries)' 기능이 2.5 Pro 및 Flash에 포함됨.

* **효율성 증대 및 비용 관리**

  * 업데이트된 2.5 Flash는 동일 성능에 필요한 토큰 수를 줄여 22%의 효율성 향상을 달성했음. 습니다. 
  * 비용 및 지연 시간 대비 품질을 제어할 수 있는 '사고 예산(thinking budgets)' 기능이 2.5 Pro에도 적용될 예정

* **AI Studio 코딩 데모:** 스케치 이미지를 기반으로 3D 애니메이션이 포함된 웹 앱을 코딩하는 시연이 있었음. Gemini의 멀티모달 이해 능력과 코딩 능력을 보여줌

* **비동기 개발 에이전트 Jules:** 버그 수정, 업데이트 등의 작업을 자율적으로 처리하는 비동기 코딩 에이전트 'Jules'가 공개 베타로 전환되었음

  * [https://labs.google.com/jules](https://labs.google.com/jules/task)

* 실험적 텍스트 확산 모델인 Gemini Diffusion

  * 병렬 생성을 활용하여 매우 낮은 지연 시간을 달성하는 실험적인 텍스트 확산 모델 'Gemini Diffusion'이 소개되었음
  * 현재 가장 빠른 모델인 2.0 Flashlight보다 5배 빠르게 코드를 생성하면서도 유사한 성능을 유지함.

  

## 8. AI 모드와 개인화된 경험인 Google 검색의 혁신

* AI Overviews는 이미 15억 명 이상의 월간 사용자를 확보했으며, 검색량 증가에 기여하고 있음

* **AI 모드 출시:** 

  * 더욱 발전된 추론 능력을 갖춘 완전히 새로운 AI 검색 경험인 'AI 모드'가 미국 사용자에게 오늘부터 제공됨. 
  * AI 모드는 Gemini 2.5로 구동되며, 사용자의 복잡하고 긴 질문에 답하고 작업을 완료하는 데 도움을 줌
  * 개인 컨텍스트 통합 (Labs): 과거 검색 기록 및 Gmail과 같은 다른 Google 앱의 정보를 선택적으로 연결하여 더욱 개인화된 응답을 제공하고 올 여름 AI Mode에 추가됨.

* **쿼리 팬아웃(Query Fan-out) 기술:** 복잡한 질문을 하위 주제로 나누고 동시에 다수의 쿼리를 실행하여 웹 전체를 깊이 검색하고, 지식 그래프, 쇼핑 그래프, 실시간 지역 데이터 등 다양한 데이터세트를 활용함

* **딥 서치(Deep Search) (Labs):** 심층적인 조사가 필요할 때 수십에서 수백 개의 검색을 실행하여 전문가 수준의 보고서를 생성함

* **복잡한 데이터 분석 및 시각화 (Labs):** 

  * 스포츠 통계나 금융 정보와 같은 복잡한 데이터를 분석하고 표나 그래프 형태로 시각화하여 제공함. 
  * 올여름 스포츠 및 금융 질문에 대해 제공될 예정

* **에이전트 기능 (Project Mariner 통합, Labs):** 행사 티켓 구매, 레스토랑 예약, 지역 서비스 약속 등 사용자를 대신하여 작업을 수행함

* **실시간 멀티모달 (Search Live, Labs):** Project Astra의 실시간 기능을 AI 모드에 통합하여 카메라를 통해 사용자가 보고 있는 것을 이해하고 실시간으로 정보를 제공함

* **향상된 쇼핑 경험 (Labs):** Google 이미지의 시각적 영감과 500억 개 이상의 제품 목록을 보유한 쇼핑 그래프를 결합하여 개인화된 쇼핑 경험을 제공함

  * **가상 착용(Virtual Try-on):** 사용자의 사진을 업로드하면 AI가 해당 옷을 착용한 모습을 보여주는 기능이 오늘부터 Labs에서 제공함
  * [데모) AI 모드로 쇼핑하고 AI를 활용해 가상으로 옷을 구매하고 입어 볼 수 있음](https://labs.google.com/search)

  * **에이전트 체크아웃:** 원하는 가격을 설정하면 가격 하락 시 알림을 받고, 사용자의 결제 및 배송 정보를 사용하여 자동으로 구매를 완료할 수 있음



## 9. Gemini AI 어시스턴트의 진화

* 개인 컨텍스트 확장: 검색 기록 외에도 Google 전반의 더 많은 개인 컨텍스트를 Gemini와 연결하여 고유한 도움을 받을 수 있게 됨.
* 능동적인 지원: 사용자가 요청하기 전에 일정을 파악하고 맞춤형 퀴즈나 설명 동영상을 제공하는 등 능동적으로 지원함
* Gemini Live 기능 확장: 카메라 및 화면 공유 기능이 Android 및 iOS의 Gemini 앱에 무료로 출시되며, 곧 캘린더, 지도, Keep, Tasks와 같은 앱과 연결될 예정
* Deep Research 및 Canvas 업데이트: 
  * 파일 업로드 기능이 추가되고, Google Drive 및 Gmail과의 연동이 예정되어 있음.
  * Canvas에서는 보고서를 웹페이지, 인포그래픽, 퀴즈, 팟캐스트 등으로 변환할 수 있음

* Gemini in Chrome: 웹 브라우징 중 현재 페이지의 컨텍스트를 이해하여 도움을 주는 AI 어시스턴트 기능 제공

* 차세대 생성 AI 미디어모델로 Vertex AI 확장

  * Imagen 4: 더 높은 품질의 이미지 생성

  * Veo 3: 오디오 및 음성을 활용한 고품질 비디오 생성
  * Lyria 2: 음악 생성을 통한 더욱 강력한 창의적 제어
  * Imagen 4 탑재: 최신 이미지 생성 모델인 Imagen 4가 Gemini 앱에 탑재되어 더욱 섬세하고 풍부한 색감의 이미지를 생성하며, 텍스트 및 타이포그래피 표현 능력이 크게 향상되었음. 기존 모델보다 10배 빠른 초고속 버전도 제공됨
  * Veo 3 공개: 
    * 네이티브 오디오 생성 기능을 갖춘 최첨단 비디오 생성 모델 Veo 3가 발표되었음. 
    * 사운드 효과, 배경음, 대화까지 생성하여 캐릭터가 말하는 비디오를 만들 수 있음

* Flow : 차세대 스토리텔링을 위해 Veo 3 를 활용한 새로운 AI 영화 제작 도구
* Gemini AI Pro ($19.99/월) : 기존 Gemini Advanced,  Gemini AI Ultra ($249.99/월) : Gemini Deep Think, Veo 3 엑세스, 유튜브 프리미엄 포함, 30TB Google Drive 지원



## 10. Android와 물리적 세계: XR의 미래

* Android XR 플랫폼
  * Gemini 시대를 위해 구축된 Android XR은 헤드셋부터 안경까지 광범위한 기기를 지원함. 
  * 삼성 및 퀄컴과의 협력을 통해 개발되었으며, 수백 명의 개발자가 이미 플랫폼용으로 빌드하고 있음
* Samsung Project Moohan (헤드셋): 첫 번째 Android XR 기기로, 무한한 화면에서 앱을 탐색하고 Gemini와 상호작용할 수 있음. 올해 말 구매 가능.
* Android XR 안경
  * 가볍고 하루 종일 착용 가능하도록 설계되었으며, 카메라, 마이크, 스피커, 선택적 인렌즈 디스플레이를 통해 Gemini가 사용자의 주변 환경을 이해하고 상호 작용함.
  * 실제 안경을 착용한 실시간 데모가 진행되어 커피숍 이름 기억, 사진 검색, 길 안내, 실시간 번역 등의 기능을 선보였음. 
  * 새로운 글래스 파트너십: Gentle Monster와 Warby Parker가 Android XR 기반 안경을 제작하는 첫 번째 안경 파트너로 발표되었음
* Firesat: 위성 이미지와 AI를 사용하여 산불을 거의 실시간으로 감지하는 시스템으로, 기존 12시간에서 20분으로 업데이트 주기를 단축하는 것을 목표로 함.
* Wing 드론 배송: 허리케인 발생 시 월마트, 적십자사와 협력하여 구호품을 드론으로 배송하는 데 AI가 활용되었음.



## 10. 결론 

* Sundar Pichai CEO는 키노트에서 AI가 95번 언급되었다고 재치있게 소개하며, AI 기술이 사회에 기여하는 사례들을 공유했습니다.
* 구글은 Gemini 2.5와 TPU Ironwood로 AI 성능과 속도를 끌어올리며, 검색·모바일·XR·개발툴 전반에 ‘에이전트화 된 경험을 대규모로 출시했음
* 털시(Tulsi)는 개발자들이 Gemini 2.5를 더 쉽게 활용할 수 있도록 향상된 텍스트-음성 변환(TTS), 강화된 보안 및 투명성과 효율성 증대 및 비용 관리, AI Studio의 코딩 데모 및 비동기 코딩 에이전트 Jules 등 개선된 기능들을 소개했음
* 죠시(Josh)는 Gemini 앱을 가장 개인적이고, 능동적이며, 강력한 AI 어시스턴트로 만들겠다는 목표를 밝혔음
* 쉬람(Shiram)은 Android가 AI를 경험하는 최고의 플랫폼이며, Gemini의 혁신이 곧 Android에 적용될 것이라고 말했음. Gemini는 시계, 자동차 대시보드, TV 등 다양한 Android 기기로 확장될 예정임
* Pichai CEO는 차세대 로봇, 질병 치료, 오류 수정 양자 컴퓨터, 완전 자율 주행 차량 등이 수십 년이 아닌 수년 내에 현실이 될 수 있다고 강조하며, 기술이 삶을 개선하고 영감을 주는 힘에 대한 기대를 표하며 키노트를 마쳤습니다.



## 11. 참고 

* [Shop with AI Mode, use AI to buy and try clothes on yourself virtually](https://blog.google/products/shopping/google-shopping-ai-mode-virtual-try-on-update/)
* [Expanding Vertex AI with the next wave of generative AI media models](https://cloud.google.com/blog/products/ai-machine-learning/announcing-veo-3-imagen-4-and-lyria-2-on-vertex-ai?hl=en)

* [Meet Flow: AI-powered filmmaking with Veo 3](https://blog.google/technology/ai/google-flow-veo-ai-filmmaking-tool/)

* [Google DeepMind Veo 3](https://deepmind.google/models/veo/)
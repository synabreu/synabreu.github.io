---
title: "지연(Latency)"
date: 2023-11-21
tags: [NVIDIA, GPU, RDMA, 지연, Latency, MPI, NCCL, RoCE, InfiniBand,A100,DeepSpeed, DeepSpeed Zero]
typora-root-url: ../
toc: true
categories: [NVIDIA, Accelerated Computing, HPC, RDMA, GPU, RoCE]
---

앞서 RDMA에 대한 글을 적으며, 한 가지 ['지연(latency)'](https://synabreu.github.io/%EC%A7%80%EC%97%B0(Latency)/)에 대한 용어에 대해 좀 더 상세히 설명해야겠다는 생각이 들었다. 왜냐하면, **지연(latency)**이란 데이터가 한 지점에서 다른 지점으로 이동하는 데 걸리는 시간을 말한다. 다시 말해, 네트워크나 시스템에서 요청(Request)이 전송된 순간부터 응답(Response)을 받을 때까지 걸리는 시간이다.



## 1. 네트워크에서 지연 시간

*  데이터 패킷이 출발지에서 목적지까지 도달하는 데 걸리는 시간
   *  예) 사용자가 웹사이트를 클릭했을 때, 웹페이지가 로드될 때까지 걸리는 시간
*  주요 원인: 
   *  거리(Distance) → 데이터가 먼 거리까지 이동할수록 지연 증가 
   *  라우팅(Routing) → 데이터가 여러 네트워크 장치를 거치면 지연 증가 
   *  네트워크 혼잡(Congestion) → 트래픽이 많을수록 패킷이 지연됨 
   *  대역폭 제한(Bandwidth Limit) → 낮은 대역폭에서는 데이터 전송 속도가 느려짐

| **지연 시간 요인**                 | **설명**                                                     |
| :--------------------------------- | :----------------------------------------------------------- |
| **전파 지연 (Propagation Delay)**  | 신호가 물리적인 전송 매체(예: 광케이블, 구리선)를 따라 이동하는 데 걸리는 시간 (거리 영향) |
| **전송 지연 (Transmission Delay)** | 데이터가 송신 측에서 네트워크를 통해 전송되는 데 걸리는 시간 (패킷 크기 및 대역폭 영향) |
| **처리 지연 (Processing Delay)**   | 라우터나 스위치에서 패킷을 수신하고 검사하며 적절한 경로로 전달하기 위한 처리 시간 |
| **대기열 지연 (Queuing Delay)**    | 네트워크 장비에서 처리 대기 중인 패킷이 대기열에 쌓이면서 발생하는 시간 (혼잡도 영향) |



## 2. 컴퓨터 시스템에서 지연 시간

*  CPU, 메모리, 스토리지, 네트워크 간 데이터 이동 속도 차이로 인해 발생하는 지연
*  주요 원인:
   *  CPU와 RAM 간 데이터 전송 속도 차이
   *  하드 디스크(HDD) vs. 반도체 저장 장치(SSD)의 데이터 접근 속도 차이
   *  GPU와 CPU 간 데이터 교환 속도



## 3. 데이터 센터의 AI 환경에서의 지연 시간

* 분산 학습(Distributed Training) 및 RDMA 네트워크에서 매우 중요한 요소 - GPU 간 데이터 교환 속도 좌우

  *  예) 256 개의 GPU가 동시에 데이터를 교환할 때 대기 시간(Latency)이 높으면 전체 AI 학습 속도가 크게 저하됨

*  주요 원인:

   1) GPU 간 내부 통신(Inter-GPU Communication)의 최적화 부족
      * **단일 서버 내에서 GPU 간 통신:** NVIDIA의 NVLink, AMD의 Infinity Fabric, Intel의 Direct Connect 등으로 해결
      * **서버 간 GPU 통신 (Cross-Node GPU Communication):** InfiniBand 또는 Ethernet 기반 RDMA(Remote Direct Memory Access) 사용

   2) RDMA(Remote Direct Memory Access) 오버헤드
   3) 케이블 길이가 길면 신호 전달 속도 저하

*  지연 시간 최적화 방법

   1) 네트워크 병목(Bottleneck) 제거 → Non-Blocking 네트워크 설계 적용
   2) RoCE (RDMA over Converged Ethernet) 사용 → TCP보다 빠른 데이터 전송
   3) NVIDIA GPUDirect 사용 → GPU 메모리 간 직접 전송 지원

   

## 4. 지연 시간을 줄이는 방법

*  일반 네트워크에서의 최적화
   *  대역폭(Bandwidth) 증대 → 100G, 400G 고속 네트워크 사용
   *  라우팅 최적화 → 네트워크 홉(Hop) 수를 줄여 데이터 이동 거리 단축
   *  QoS (Quality of Service) 적용 → 중요 트래픽을 우선 처리
*  HPC&AI 환경에서의 최적화
   *  RDMA 기반 네트워크 사용 (RoCE, InfiniBand)
   *  NVLink/NVSwitch 같은 GPU 전용 네트워크 활용
   *  스파인-리프(Spine-Leaf) 네트워크 설계로 병목 제거



## 5. 용어 설명

*   **inter-node communication**과 **cross-node communication**은 **동일한 의미**

   *  서로 다른 물리적 노드(서버, 머신)에 있는 GPU 또는 프로세스 간의 통신

   *  **"Inter-node"**는 **기술 문서나 논문**에서 더 자주 사용됨 (예: NCCL 공식 문서, PyTorch DDP 설명 등)

   *  **"Cross-node"**는 설명의 **직관성을 높이기 위해** 일부 커뮤니티나 튜토리얼에서 사용됨

   *  **Inter-node (또는 Cross-node)**:

      - Node 0: GPU0, GPU1
      - Node 1: GPU2, GPU3
         → GPU1이 GPU2와 통신하는 경우 → **inter-node / cross-node**

   *  **Intra-node**:

      - GPU0 ↔ GPU1 (같은 머신) → intra-node

      

## 6. 결론

*  지연은 AI 및 데이터센터에서 가장 중요한 요소 중 하나 -> 네트워크 및 시스템 성능을 결정하는 핵심 지표
*  AI 및 HPC 환경에서는 낮은 저지연(low latency)가 필수
*  네트워크 설계(Network Topology), RDMA 기술, 케이블 배선 최적화를 통해 최소화해야 함

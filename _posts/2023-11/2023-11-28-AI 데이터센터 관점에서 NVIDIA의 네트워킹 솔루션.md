---
title: "AI 데이터센터 관점에서 NVIDIA의 네트워킹 솔루션
date: 2023-11-28
tags: [NVIDIA, GPU, CUDA, Quantum Infiniband, Spectrum-X Ethernet, BlueField-3 DPU, RoCE]
typora-root-url: ../
---

NVIDIA는 Quantum Infiniband 및 Spectrum-X Ethernet을 통해 세계에서 가장 높은 성능의 AI 네트워크 솔루션을 제공하고, 메모리 패브릭 네트워크 인프라 구축 시 적극 고려해야 하는 데, AI 데이터센터 관점에서 NVIDIA의 네트워킹 솔루션에 대해 알아보도록 하자. 



## 1. **NVIDIA CUDA Toolkit 12.8**

| 항목           | AI 팩토리                                                    | AI 클라우드                                      |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------ |
| 주요 항목      | 대규모 언어 모델(LLM) 훈련                                   | 다수 사용자를 지원하는 초대형(Hyperscale) 시스템 |
|                | 디지털 트윈 등 고성능 연산 작업                              | 멀티 테넌트 환경 제공                            |
|                | AI 슈퍼컴퓨터 구축을 통한 거대·복잡한 AI 모델 훈련 및 최적화 | 상대적으로 덜 복잡한 소규모 작업 실행            |
| 연산 성능 요구 | 매우 높은 연산 성능 요구                                     | 상대적으로 낮은 연산 성능 요구                   |
| 네트워크 구성  | 전용 네트워크 필요                                           | 이더넷(Ethernet) 기반 네트워크 활용              |
|                | 서버 내 DPU 간 통신: NVLink                                  | 멀티 테넌트 환경 운영                            |
|                | 서버 간 GPU 통신: Infiniband                                 |                                                  |



##  2. 기존 네트워크의 한계와 NVIDIA의 해결책

* 기존 네트워크 한계

  - AI 워크로드는 기존 클라우드 및 인터넷 인프라에서 실행할 경우, 대량의 네트워크 트래픽을 생성하여 네트워크 인프라에 큰 영향을 미침.

  - 이로 인해 혼잡(Congestion), 지연 증가(Latency), 대역폭 불균형(Bandwidth Unfairness) 문제가 발생헤 시스템의 GPU를 효율적으로 활용하지 못함

* NVIDIA 네트워크 해결책

  * Quantum Infiniband – 대규모 AI 팩토리를 위한 초고성능 네트워크
  * Spectrum-X Ethernet – 생성형 AI 클라우드(Generative AI Cloud) 가속을 위한 솔루션

##  3. Quantum Infiniband

* 정의 : 딥러닝, 과학연산, AI 추론, 고성능 컴퓨팅(HPC) 환경을 대상으로 데이터 집약적인 시뮬레이션, 분석 애플리케이션, HPC, 슈퍼컴퓨팅에 최적화된 네트워크
* 주요 특징
  - 400Gbps의 초고속 대역폭(NDR) 지원
  - 업계 최저 수준의 지연 증가(Latency)
  - QoS(Quality of Service), 적응형 라우팅(Adaptive Routing), 혼잡 제어(Congestion Control) 지원
  - 하드웨어 기반 RDMA를 통해 CPU 개입 없이 데이터 이동 가능
  - 32배의 AI 가속 성능 및 최대 6.5배의 확장성 향상
  - 투자 대비 효과(ROI) 및 전반적인 투자 가치 개선



### 4. Spectrum-X Ethernet

* 정의 :
  - 생성형 AI 클라우드 가속을 위해 설계된 최초의 이더넷 플랫폼
  - Spectrum-X를 기반으로 한 전용 패브릭 구축은 새로운 AI 클라우드를 구현하려는 고객들에게 최적의 선택
* 장점
  - 95%의 네트워크 효율적인 대역폭
  - 전통적인 이더넷 대비 1.6배 증가한 AI 네트워크 성능



### 5. NVIDIA 네트워크 플랫폼

* Quantum X800 Infiniband – 대규모 AI 시스템을 위한 차세대 플랫폼
* BlueField-3 DPU – 네트워크, 스토리지, 보안을 통합한 데이터센터 가속 솔루션
* Spectrum-X Ethernet - AI 클라우드 성능을 극대화하기 위한 이더넷 플랫폼
* 네트워크 연결 방식에 따라
  - North-South 네트워크: 서버-클라이언트 연결
  - East-West 네트워크: GPU-GPU 연결. 고속, 손실 없는 통신 요구. NVIDIA의 RDMA 기반 Infiniband 및 RoCE(RDMA over Converged Ethernet) 기술 활용



### 6. Quantum-2 및 차세대 Infiniband

* 현재 NVIDIA는 Quantum-2 Infiniband 솔루션 제공
* 차세대 Quantum-X800(800Gbps) 기술 개발 중 - 기존 대비 5배 확장성 증가, 4.4 테라플롭스의 네트워크 컴퓨팅 성능 제공



### 7. Spectrum-X 및 RoCE 기반 AI 네트워킹

* Spectrum-X는 RoCE 확장 기술을 활용하여 AI 클라우드 성능을 극대화
* 4.3배 증가한 대역폭, 2.2배 낮은 지연증 구현
* 예) 256대의 서버와 2,048개의 H100 GPU로 구성된 이스라엘 AI 클러스터(Israel-1)를 구축하여, Spectum-X 기반의 AI 네트워크 성능을 최적화

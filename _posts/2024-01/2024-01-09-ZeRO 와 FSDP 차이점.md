---
title: "ZeRO 와 FSDP 차이점"
date: 2024-01-09
tags: [DeepSpeed, 딥스피드, Microsoft, 마이크로소프트, PyTorch, ZeRO optimizer, Mixed Precision, Model Parallelism, Pipeline Parallelism, DeepSpeed-Inference, DDP, Distributed Data Parallel]
typora-root-url: ../

---



ZeRO(Zero Redundancy Optimizer)와 FSDP(Fully Sharded Data Parallel)는 모두 **PyTorch 기반의 분산 학습을 위한 메모리 효율 최적화 기법**이다. 두 기법은 유사한 목표를 가지고 있지만, 설계 철학과 구현 방식에서 다음과 같은 **중요한 차이점**이 있다. 



## 1. 구현 주체

| 항목      | ZeRO                        | FSDP                                    |
| --------- | --------------------------- | --------------------------------------- |
| 개발 주체 | Microsoft DeepSpeed         | Meta (PyTorch 공식)                     |
| 구현 위치 | DeepSpeed 라이브러리 (외부) | PyTorch 내부 (`torch.distributed.fsdp`) |
| 설치 필요 | `deepspeed` 설치 필요       | PyTorch만 설치하면 사용 가능            |



## 2. 메모리 분산 방식

| 항목      | ZeRO                                                     | FSDP                                                     |
| --------- | -------------------------------------------------------- | -------------------------------------------------------- |
| 전략      | 모델 파라미터, gradient, optimizer state를 **분산 저장** | 모델 파라미터 자체를 **샤딩(Sharding)** 하여 GPU 간 분할 |
| 기본 구조 | 기존 DDP 위에 최적화 단계를 추가한 구조                  | 완전한 파라미터 샤딩 구조로, DDP와 다름                  |
| 통신 방식 | 주로 NCCL AllGather / ReduceScatter                      | AllGather during fwd, ReduceScatter during bwd           |



## 3. 모델 파라미터 로딩 방식

| 항목                     | ZeRO                                     | FSDP                                     |
| ------------------------ | ---------------------------------------- | ---------------------------------------- |
| forward 시 모델 파라미터 | 일부 stage에 따라 broadcast 후 전체 로드 | 필요한 시점에 해당 파라미터만 all-gather |
| backward 시 gradient     | ReduceScatter 등으로 분산                | ReduceScatter로 바로 분산 저장           |



## 4. 사용의 유연성과 복잡도

| 항목          | ZeRO                                        | FSDP                                   |
| ------------- | ------------------------------------------- | -------------------------------------- |
| 커스터마이징  | 다양한 ZeRO stage (1, 2, 3) 존재 → 복잡     | 비교적 일관된 API (`wrap(model)` 형태) |
| 초기 진입장벽 | DeepSpeed config JSON, CLI 등 진입장벽 있음 | PyTorch 내부 기능 → 진입장벽 낮음      |



## 5. 지원 기능 차이

| 항목            | ZeRO                                               | FSDP                                               |
| --------------- | -------------------------------------------------- | -------------------------------------------------- |
| Checkpointing   | Offload, CPU, NVMe 지원 (ZeRO-Offload)             | PyTorch 2.0 이후, `state_dict_type=...`으로 지원   |
| Mixed Precision | FP16, BF16 지원, ZeRO-Infinity로 NVMe offload까지  | Mixed precision 자동 지원 (`MixedPrecisionPolicy`) |
| 비동기화 기능   | ZeRO-Infinity, Offload, Stage-3 optimizer sharding | 최근 PyTorch에서 FSDP CPU offload 지원 추가        |



## 6. 결론

| 상황                                           | 추천 방식                                      |
| ---------------------------------------------- | ---------------------------------------------- |
| PyTorch 기본으로 통합된 방식을 원할 때         | ✅ **FSDP** (설치 간단, PyTorch 공식)           |
| 대규모 모델, Offloading, 복잡한 최적화 필요 시 | ✅ **ZeRO (DeepSpeed)** (더 많은 기능과 확장성) |
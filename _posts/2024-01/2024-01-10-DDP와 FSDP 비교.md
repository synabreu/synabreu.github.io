---
title: "DDP와 FSDP 비교"
date: 2024-01-10
tags: [DeepSpeed, 딥스피드, Microsoft, 마이크로소프트, PyTorch, ZeRO optimizer, Mixed Precision, Model Parallelism, Pipeline Parallelism, DeepSpeed-Inference, DDP, Distributed Data Parallel]
typora-root-url: ../
toc: true
categories: [DDP, FSDP, PyTorch, Distributed Training, Multi GPU, Multi Node]
---

DDP(DistributedDataParallel)와 FSDP(FullyShardedDataParallel)는 둘 다 PyTorch에서 **멀티 GPU 분산 학습**을 위한 기법이지만, **메모리 사용 방식**과 **모델 분할 전략**에서 차이가 있다. 그래서 다음과 같이 비교를 해보자! 



## 1. DDP (DistributedDataParallel)

| 항목            | 설명                                                         |
| --------------- | ------------------------------------------------------------ |
| **동작 방식**   | 각 GPU에 모델 전체를 **복제**하고, forward/backward 후 gradient를 **AllReduce**로 동기화 |
| **메모리 사용** | 모든 GPU에 **전체 모델이 올라감**                            |
| **장점**        | 구현이 간단하고 빠름. 대부분의 상황에서 충분히 성능이 좋음   |
| **단점**        | 모델이 클 경우, **GPU 메모리에 제한**이 생김 (모델 크기 > GPU 메모리 X 불가) |
| **사용 예**     | 일반적인 멀티 GPU 학습 상황                                  |



## 2. FSDP (Fully Sharded Data Parallel)

| 항목            | 설명                                                         |
| --------------- | ------------------------------------------------------------ |
| **동작 방식**   | 모델 파라미터, gradient, optimizer state를 GPU 간에 **shard(조각)** 해서 나눠 가짐 |
| **메모리 사용** | 한 GPU에는 **전체 모델의 일부만 올라감**                     |
| **장점**        | 매우 큰 모델도 **단일 GPU 메모리 한계 없이 학습 가능**       |
| **단점**        | 구현 복잡, 일부 연산에서 속도 손해 발생 가능. 초기 설정이 까다로움 |
| **사용 예**     | GPT, LLaMA, BLOOM 같은 **초거대 LLM 훈련**에 적합            |



## 3. DDP vs. FSDP 

| 항목               | DDP                  | FSDP                                       |
| ------------------ | -------------------- | ------------------------------------------ |
| 모델 복제          | 모든 GPU에 전체 모델 | 모델을 GPU 간 나눠 저장                    |
| 메모리 효율        | 낮음                 | 높음                                       |
| 통신량             | gradient AllReduce만 | shard된 weight, grad, optimizer state 모두 |
| 초기화 및 구현     | 간단                 | 복잡                                       |
| 대규모 모델 적합성 | 낮음                 | 매우 높음                                  |



## 4. 결론 

* **모델이 작거나 중간 규모** → `DDP`가 적절.
* **수십억~수천억 파라미터 모델** → `FSDP` 필수.

